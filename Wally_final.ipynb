{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpxLPywSD31dwqtYwp4Yb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdarshSRM/FirstSite/blob/main/Wally_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1U4iterNsza",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Create the text box and button\n",
        "url_input = widgets.Text(placeholder='Paste URL here', description='URL:')\n",
        "button = widgets.Button(description=\"Set URL\", button_style='success')\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    global TARGET_URL\n",
        "    TARGET_URL = url_input.value.strip()\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        if TARGET_URL:\n",
        "            print(f\"✅ Set to: {TARGET_URL}\")\n",
        "        else:\n",
        "            print(\"❌ Please paste a URL first.\")\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "\n",
        "# Display everything\n",
        "display(url_input, button, output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "to_remove = ['downloads', 'imagebam_links.txt', 'result_images.zip']\n",
        "\n",
        "for item in to_remove:\n",
        "    if os.path.exists(item):\n",
        "        if os.path.isdir(item):\n",
        "            shutil.rmtree(item)\n",
        "            print(f\"Removed folder: {item}\")\n",
        "        else:\n",
        "            os.remove(item)\n",
        "            print(f\"Removed file: {item}\")\n",
        "\n",
        "print(\"Cleanup complete. Ready for new extraction.\")"
      ],
      "metadata": {
        "id": "oQ9U9HT9N2DM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_links():\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"}\n",
        "    print(f\"Fetching links from: {TARGET_URL}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(TARGET_URL, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract links in order and remove duplicates\n",
        "        links = [a['href'] for a in soup.find_all('a', href=True) if \"imagebam.com/image/\" in a['href']]\n",
        "        unique_links = list(dict.fromkeys(links))\n",
        "\n",
        "        if unique_links:\n",
        "            with open(\"imagebam_links.txt\", \"w\") as f:\n",
        "                for link in unique_links:\n",
        "                    f.write(link + \"\\n\")\n",
        "            print(f\"Success! Found {len(unique_links)} links. Saved to 'imagebam_links.txt'.\")\n",
        "        else:\n",
        "            print(\"No ImageBam links found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "scrape_links()"
      ],
      "metadata": {
        "id": "bHxll8qgN3_o",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "\n",
        "os.makedirs(\"downloads\", exist_ok=True)\n",
        "\n",
        "def resolve_direct_link(session, url):\n",
        "    # Force HTTPS\n",
        "    url = url.replace(\"http://\", \"https://\")\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\",\n",
        "        \"Referer\": \"https://www.imagebam.com/\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # 1. SET THE MAGIC COOKIES\n",
        "        # The logs show 'sfw_inter' is the key to bypassing the 'Continue' loop\n",
        "        session.cookies.set(\"sfw_inter\", \"1\", domain=\".imagebam.com\")\n",
        "        session.cookies.set(\"nsfw_inter\", \"1\", domain=\".imagebam.com\")\n",
        "\n",
        "        # 2. GET the page\n",
        "        # With the cookies set, this should bypass the interstitial immediately\n",
        "        response = session.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # 3. SEARCH for the image\n",
        "        # Using the standard ID and the class found in Imagebam's app.js logic\n",
        "        img = soup.find('img', id='main-image') or soup.select_one('img.main-image')\n",
        "\n",
        "        if not img:\n",
        "            # Fallback: search for any image hosted on their image servers\n",
        "            img = soup.select_one('img[src*=\"images2.imagebam.com\"]')\n",
        "\n",
        "        if img:\n",
        "            return img.get('src')\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   [Error]: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_images():\n",
        "    if not os.path.exists(\"imagebam_links.txt\"):\n",
        "        print(\"Error: imagebam_links.txt not found!\")\n",
        "        return\n",
        "\n",
        "    with open(\"imagebam_links.txt\", \"r\") as f:\n",
        "        urls = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    print(f\"Downloading {len(urls)} images...\")\n",
        "    for index, url in enumerate(urls, start=1):\n",
        "        try:\n",
        "            print(f\"[{index}/{len(urls)}] Processing: {url}\")\n",
        "            direct_url = resolve_direct_link(session, url)\n",
        "\n",
        "            if direct_url:\n",
        "                # Use the original URL as Referer to avoid 403 Forbidden on the image file\n",
        "                img_response = session.get(direct_url, headers={\"Referer\": url})\n",
        "\n",
        "                original_id = url.split('/')[-1]\n",
        "                filename = f\"downloads/{index}-{original_id}.jpg\"\n",
        "\n",
        "                with open(filename, 'wb') as f:\n",
        "                    f.write(img_response.content)\n",
        "                print(f\"   -> Saved!\")\n",
        "            else:\n",
        "                print(f\"   -> Failed: Still seeing the 'Continue' page loop.\")\n",
        "\n",
        "            time.sleep(1.2)\n",
        "        except Exception as e:\n",
        "            print(f\"   -> Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_images()"
      ],
      "metadata": {
        "id": "lu15GPKJN7Wk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if os.path.exists(\"downloads\") and len(os.listdir(\"downloads\")) > 0:\n",
        "    print(\"Zipping files...\")\n",
        "    !zip -q -r result_images.zip downloads\n",
        "    print(\"Download starting...\")\n",
        "    files.download('result_images.zip')\n",
        "else:\n",
        "    print(\"Nothing to zip. Make sure the download cell (Cell 4) finished successfully.\")"
      ],
      "metadata": {
        "id": "VGcbLxVxN_oI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}